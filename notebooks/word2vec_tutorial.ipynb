{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec + keras Tutorial\n",
    "\n",
    "Code taken from https://www.kaggle.com/marijakekic/cnn-in-keras-with-pretrained-word2vec-weights\n",
    "\n",
    "\n",
    "To see only word2vec: https://rare-technologies.com/word2vec-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-30 14:37:14,918 : INFO : collecting all words and their counts\n",
      "2018-04-30 14:37:14,921 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-04-30 14:37:14,923 : INFO : collected 3 word types from a corpus of 4 raw words and 2 sentences\n",
      "2018-04-30 14:37:14,925 : INFO : Loading a fresh vocabulary\n",
      "2018-04-30 14:37:14,925 : INFO : min_count=1 retains 3 unique words (100% of original 3, drops 0)\n",
      "2018-04-30 14:37:14,926 : INFO : min_count=1 leaves 4 word corpus (100% of original 4, drops 0)\n",
      "2018-04-30 14:37:14,927 : INFO : deleting the raw counts dictionary of 3 items\n",
      "2018-04-30 14:37:14,928 : INFO : sample=0.001 downsamples 3 most-common words\n",
      "2018-04-30 14:37:14,929 : INFO : downsampling leaves estimated 0 word corpus (5.7% of prior 4)\n",
      "2018-04-30 14:37:14,929 : INFO : estimated required memory for 3 words and 100 dimensions: 3900 bytes\n",
      "2018-04-30 14:37:14,931 : INFO : resetting layer weights\n",
      "2018-04-30 14:37:14,933 : INFO : training model with 3 workers on 3 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-04-30 14:37:14,935 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-30 14:37:14,936 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-30 14:37:14,937 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-30 14:37:14,938 : INFO : EPOCH - 1 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2018-04-30 14:37:14,943 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-30 14:37:14,944 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-30 14:37:14,946 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-30 14:37:14,947 : INFO : EPOCH - 2 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2018-04-30 14:37:14,948 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-30 14:37:14,949 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-30 14:37:14,949 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-30 14:37:14,950 : INFO : EPOCH - 3 : training on 4 raw words (1 effective words) took 0.0s, 571 effective words/s\n",
      "2018-04-30 14:37:14,952 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-30 14:37:14,953 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-30 14:37:14,953 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-30 14:37:14,954 : INFO : EPOCH - 4 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2018-04-30 14:37:14,959 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-30 14:37:14,960 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-30 14:37:14,962 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-30 14:37:14,963 : INFO : EPOCH - 5 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2018-04-30 14:37:14,964 : INFO : training on a 20 raw words (1 effective words) took 0.0s, 33 effective words/s\n",
      "2018-04-30 14:37:14,964 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "# import modules & set up logging\n",
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    " \n",
    "sentences = [['first', 'sentence'], ['second', 'sentence']]\n",
    "# train word2vec on the two sentences\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('arma', 17), ('viene', 11), ('te', 13), ('abuela', 20), ('ahi', 15), ('bardo', 18), ('luego', 10), ('se', 16), ('hola', 9), ('chancleta', 23), ('corre', 5), ('bar', 7), ('baz', 8), ('hasta', 21), ('la', 4), ('consigue', 22), ('pega', 14), ('que', 1), ('foo', 6), ('mono', 12), ('el', 2), ('y', 3), ('con', 19)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  6,  7,  8,  9],\n",
       "       [ 0,  0, 10, 11,  2, 12,  1, 13, 14],\n",
       "       [ 3, 15, 16, 17,  2, 18, 19,  4, 20],\n",
       "       [ 1,  5,  3,  5, 21,  1, 22,  4, 23]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"\"\"Foo bar baz hola\n",
    "luego viene el mono que te pega\n",
    "y ahi se arma el bardo con la abuela\n",
    "que corre y corre hasta que consigue la chancleta\"\"\"\n",
    "\n",
    "sentences = t.split('\\n')\n",
    "#sentences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=30, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\'', lower=True, \n",
    "                      char_level=False, split=' ')\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "print(tokenizer.word_index.items())\n",
    "\n",
    "padded = pad_sequences(sequences)\n",
    "padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-30 16:27:55,426 : INFO : loading projection weights from ../../datasets/wordembed/GoogleNews-vectors-negative300.bin.gz\n",
      "2018-04-30 16:30:15,943 : INFO : loaded (3000000, 300) matrix from ../../datasets/wordembed/GoogleNews-vectors-negative300.bin.gz\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "word_vectors = KeyedVectors.load_word2vec_format('../../datasets/wordembed/GoogleNews-vectors-negative300.bin.gz', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = word_vectors.get_keras_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activity_regularizer': None,\n",
       " 'batch_input_shape': (None, None),\n",
       " 'dtype': 'float32',\n",
       " 'embeddings_constraint': None,\n",
       " 'embeddings_initializer': {'class_name': 'RandomUniform',\n",
       "  'config': {'maxval': 0.05, 'minval': -0.05, 'seed': None}},\n",
       " 'embeddings_regularizer': None,\n",
       " 'input_dim': 3000000,\n",
       " 'input_length': 60,\n",
       " 'mask_zero': False,\n",
       " 'name': 'embedding_1',\n",
       " 'output_dim': 300,\n",
       " 'trainable': False}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.input_length = 60\n",
    "embed.get_config()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
